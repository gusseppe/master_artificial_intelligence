{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "s6_Gusseppe_Bravo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zVU-eQKO_B1",
        "colab_type": "text"
      },
      "source": [
        "# Word Sense Disambiguation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHwy3WXbRtEv",
        "colab_type": "text"
      },
      "source": [
        "# Lab Session 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joIJ7lxQs0Fx",
        "colab_type": "text"
      },
      "source": [
        "### Mandatory exercise\n",
        "\n",
        "https://gebakx.github.io/ihlt/s6/index.html#7\n",
        "\n",
        "**Statement:**\n",
        "\n",
        "- Read all pairs of sentences of the trial set within the evaluation framework of the project.\n",
        "\n",
        "- Apply Lesk’s algorithm to the words in the sentences.\n",
        "\n",
        "- Compute their similarities by considering senses and Jaccard coefficient.\n",
        "\n",
        "- Compare the results with those in session 2 (document) and 3 (morphology) in which words and lemmas were considered.\n",
        "\n",
        "- Compare the results with gold standard by giving the pearson correlation between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EacLQzOQtW-F",
        "colab_type": "text"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGsJR4CUtMO-",
        "colab_type": "text"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "Only in case nltk and the file do not exist in the current computer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfSBd7nytOsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "import nltk\n",
        "nltk.download() # 1. d | 2. book | 3. q\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "!wget https://gebakx.github.io/ihlt/s6/resources/trial.tgz\n",
        "\n",
        "with tarfile.open('trial.tgz', \"r:gz\") as tar:\n",
        "  tar.extractall()\n",
        "\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxllOkhdRj3i",
        "colab_type": "text"
      },
      "source": [
        "## Input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6XaF66PRiTn",
        "colab_type": "code",
        "outputId": "72e9d696-6c8f-4b55-cf07-afc0e8cac59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "trial_data = pd.read_csv('trial/STS.input.txt', sep='\\t', \n",
        "                         names=['id', 'sent1', 'sent2'])\n",
        "trial_data = trial_data.astype(str)                \n",
        "trial_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id1</td>\n",
              "      <td>The bird is bathing in the sink.</td>\n",
              "      <td>Birdie is washing itself in the water basin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id2</td>\n",
              "      <td>In May 2010, the troops attempted to invade Ka...</td>\n",
              "      <td>The US army invaded Kabul on May 7th last year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id3</td>\n",
              "      <td>John said he is considered a witness but not a...</td>\n",
              "      <td>He is not a suspect anymore. John said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id4</td>\n",
              "      <td>They flew out of the nest in groups.</td>\n",
              "      <td>They flew into the nest together.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id5</td>\n",
              "      <td>The woman is playing the violin.</td>\n",
              "      <td>The young lady enjoys listening to the guitar.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>id6</td>\n",
              "      <td>John went horse back riding at dawn with a who...</td>\n",
              "      <td>Sunrise at dawn is a magnificent view to take ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ...                                              sent2\n",
              "0  id1  ...       Birdie is washing itself in the water basin.\n",
              "1  id2  ...  The US army invaded Kabul on May 7th last year...\n",
              "2  id3  ...            He is not a suspect anymore. John said.\n",
              "3  id4  ...                  They flew into the nest together.\n",
              "4  id5  ...     The young lady enjoys listening to the guitar.\n",
              "5  id6  ...  Sunrise at dawn is a magnificent view to take ...\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5T5_eTxRyUt",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing: Tagging and lemmatization\n",
        "\n",
        "Steps:\n",
        "\n",
        "- Tokenize the sentence.\n",
        "- Tag each word as a Part of speech (POS)\n",
        "- Word sense disambiguation: Lesk\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLeFtxGkc9QY",
        "colab_type": "text"
      },
      "source": [
        "## Mapping pos tags to wordnet tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cqy9xgOtlOj",
        "colab_type": "text"
      },
      "source": [
        "The way POS-tag works is different from how wordnet does.\n",
        "\n",
        "This mapping is needed when working with synsets from wordnet, such as, lemmatizer, lesk, you name it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSH1JLScakFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def map_pos_wordnet(pos):\n",
        "  d = {\"N\": wordnet.NOUN, # 'n'\n",
        "       \"V\": wordnet.VERB, # 'v'\n",
        "       \"J\": wordnet.ADJ, #  'a'\n",
        "       \"R\": wordnet.ADV} #  'r'\n",
        "\n",
        "\n",
        "  return d[pos[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4rT6Jdzd8um",
        "colab_type": "text"
      },
      "source": [
        "## Calculate lesk algorithm to each sentence\n",
        "\n",
        "Let's find the sense of a word given its context by using the lesk algorithm.\n",
        "\n",
        "Sometimes lesk yields a synset and others does not. It happens because of the existence of that word in wordnet either with POS or not, or even if it exists as a valid word.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OakFHgcAXgN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.wsd import lesk\n",
        "\n",
        "\n",
        "def wsd_lesk(pairs, if_lesk_null='no_pos'):\n",
        "  result = []\n",
        "  context = dict(pairs).keys()\n",
        "  for (token, pos) in pairs:\n",
        "    # print(token, pos)\n",
        "    if pos[0] in {'N','V', 'J', 'R'}:\n",
        "      synset = lesk(context, token.lower(), pos=map_pos_wordnet(pos))\n",
        "      # try if synset exists with pos tag\n",
        "      if synset is not None:\n",
        "        result.append(synset.name().split('.')[0])\n",
        "      # try if synset exists without pos tag\n",
        "      else:\n",
        "        # calculate lesk without considering pos\n",
        "        if if_lesk_null=='no_pos':\n",
        "          synset = lesk(context, token.lower())\n",
        "\n",
        "          # if synset doesn't exist at all\n",
        "          if synset is None:\n",
        "            result.append(token) \n",
        "          else:\n",
        "            result.append(synset.name().split('.')[0])\n",
        "        else:\n",
        "          result.append(token)\n",
        "    else:\n",
        "      result.append(token)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7dH0BxnW1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk.help.upenn_tagset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY-u7lWAMODf",
        "colab_type": "code",
        "outputId": "181b2492-12fc-45ae-a5a3-1995fc06b278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "for col in ['sent1', 'sent2']:\n",
        "  trial_data[col+'_processed'] = trial_data[col].apply(nltk.word_tokenize)\n",
        "  trial_data[col+'_processed'] = trial_data[col+'_processed'].apply(nltk.pos_tag)\n",
        "  trial_data[col+'_processed'] = trial_data[col+'_processed'].apply(wsd_lesk, if_lesk_null='nothing')\n",
        "\n",
        "trial_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>sent1_processed</th>\n",
              "      <th>sent2_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id1</td>\n",
              "      <td>The bird is bathing in the sink.</td>\n",
              "      <td>Birdie is washing itself in the water basin.</td>\n",
              "      <td>[The, bird, be, bathe, in, the, sinkhole, .]</td>\n",
              "      <td>[shuttlecock, be, wash, itself, in, the, body_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id2</td>\n",
              "      <td>In May 2010, the troops attempted to invade Ka...</td>\n",
              "      <td>The US army invaded Kabul on May 7th last year...</td>\n",
              "      <td>[In, whitethorn, 2010, ,, the, troop, undertak...</td>\n",
              "      <td>[The, uranium, united_states_army, invade, kab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id3</td>\n",
              "      <td>John said he is considered a witness but not a...</td>\n",
              "      <td>He is not a suspect anymore. John said.</td>\n",
              "      <td>[whoremaster, suppose, he, embody, view, a, wi...</td>\n",
              "      <td>[He, embody, not, a, defendant, anymore, ., wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id4</td>\n",
              "      <td>They flew out of the nest in groups.</td>\n",
              "      <td>They flew into the nest together.</td>\n",
              "      <td>[They, fly, out, of, the, nest, in, group, .]</td>\n",
              "      <td>[They, fly, into, the, nest, together, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id5</td>\n",
              "      <td>The woman is playing the violin.</td>\n",
              "      <td>The young lady enjoys listening to the guitar.</td>\n",
              "      <td>[The, woman, be, play, the, violin, .]</td>\n",
              "      <td>[The, young, lady, love, heed, to, the, guitar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>id6</td>\n",
              "      <td>John went horse back riding at dawn with a who...</td>\n",
              "      <td>Sunrise at dawn is a magnificent view to take ...</td>\n",
              "      <td>[toilet, plump, knight, back, ride, at, dawn, ...</td>\n",
              "      <td>[sunrise, at, dawn, be, a, magnificent, view, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ...                                    sent2_processed\n",
              "0  id1  ...  [shuttlecock, be, wash, itself, in, the, body_...\n",
              "1  id2  ...  [The, uranium, united_states_army, invade, kab...\n",
              "2  id3  ...  [He, embody, not, a, defendant, anymore, ., wh...\n",
              "3  id4  ...          [They, fly, into, the, nest, together, .]\n",
              "4  id5  ...  [The, young, lady, love, heed, to, the, guitar...\n",
              "5  id6  ...  [sunrise, at, dawn, be, a, magnificent, view, ...\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4FeOQeyPgRf",
        "colab_type": "text"
      },
      "source": [
        "## Calculating the Jacard distance\n",
        "\n",
        "It measures how close or far are the given sentences, it is a not so robust way to measure two equivalents sentences. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRMOs4EdPcfr",
        "colab_type": "code",
        "outputId": "c3d51b64-4aa0-4446-82d7-475ca4868bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "result = []\n",
        "\n",
        "for index, row in trial_data.iterrows():\n",
        "  result.append(jaccard_distance(set(row['sent1_processed']),\n",
        "                             set(row['sent2_processed'])))\n",
        "\n",
        "result = 1 - np.array(result)\n",
        "result"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.30769231, 0.33333333, 0.53846154, 0.45454545, 0.23076923,\n",
              "       0.13793103])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYUC3QJIP7HE",
        "colab_type": "text"
      },
      "source": [
        "## Calculating the Pearson correlation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l55zfo3kPjgF",
        "colab_type": "code",
        "outputId": "0a44d7e6-8160-4c5d-ed6a-94b8e4913fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "gs = pd.read_csv('trial/STS.gs.txt', sep='\\t', header=None)\n",
        "refs = list(reversed(gs[1].values))\n",
        "print(f'Gold standard: {refs}')\n",
        "tsts = result * 5\n",
        "print(f'Jaccard distance: {tsts}')\n",
        "print(f'Pearson correlation: {pearsonr(refs, tsts)[0]}')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gold standard: [5, 4, 3, 2, 1, 0]\n",
            "Jaccard distance: [1.53846154 1.66666667 2.69230769 2.27272727 1.15384615 0.68965517]\n",
            "Pearson correlation: 0.45509668497522504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_6geqzDkl9m",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate against training data set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjbx7-HWuURH",
        "colab_type": "text"
      },
      "source": [
        "### Download and read training data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g16rtXZSuUrz",
        "colab_type": "code",
        "outputId": "4ae85076-b135-46bd-9b7f-27aad67f754e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "url_train = 'https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train.tgz'\n",
        "!wget $url_train\n",
        "\n",
        "with tarfile.open('train.tgz', \"r:gz\") as tar:\n",
        "  tar.extractall()\n",
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-19 17:24:52--  https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train.tgz\n",
            "Resolving www.cs.york.ac.uk (www.cs.york.ac.uk)... 144.32.128.40\n",
            "Connecting to www.cs.york.ac.uk (www.cs.york.ac.uk)|144.32.128.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125822 (123K) [application/x-gzip]\n",
            "Saving to: ‘train.tgz’\n",
            "\n",
            "train.tgz           100%[===================>] 122.87K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-19 17:24:53 (1.13 MB/s) - ‘train.tgz’ saved [125822/125822]\n",
            "\n",
            "sample_data  train  train.tgz  trial  trial.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlhWthMhuWoP",
        "colab_type": "code",
        "outputId": "9c3be3c9-144b-4799-9f71-02f45c75904d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('train/STS.input.MSRvid.txt', sep='\\t', names=['sent1', 'sent2'])\n",
        "print(f'# rows: {len(train_data)}')\n",
        "train_data = train_data.astype(str)                \n",
        "train_data.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# rows: 750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A man is riding a bicycle.</td>\n",
              "      <td>A man is riding a bike.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A woman and man are dancing in the rain.</td>\n",
              "      <td>A man and woman are dancing in rain.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Someone is drawing.</td>\n",
              "      <td>Someone is dancing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A man and a woman are kissing each other.</td>\n",
              "      <td>A man and a woman are talking to each other.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A woman is slicing an onion.</td>\n",
              "      <td>A woman is cutting an onion.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       sent1                                         sent2\n",
              "0                 A man is riding a bicycle.                       A man is riding a bike.\n",
              "1   A woman and man are dancing in the rain.          A man and woman are dancing in rain.\n",
              "2                        Someone is drawing.                           Someone is dancing.\n",
              "3  A man and a woman are kissing each other.  A man and a woman are talking to each other.\n",
              "4               A woman is slicing an onion.                  A woman is cutting an onion."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q_CH2dMugL6",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process the input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTn60TKDubVS",
        "colab_type": "code",
        "outputId": "f5d30d48-cf10-48f6-ea69-9d8fc468c641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for col in ['sent1', 'sent2']:\n",
        "  train_data[col+'_processed'] = train_data[col].apply(nltk.word_tokenize)\n",
        "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(nltk.pos_tag)\n",
        "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(wsd_lesk, if_lesk_null='no_pos')\n",
        "\n",
        "train_data.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>sent1_processed</th>\n",
              "      <th>sent2_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A man is riding a bicycle.</td>\n",
              "      <td>A man is riding a bike.</td>\n",
              "      <td>[A, man, embody, ride, a, bicycle, .]</td>\n",
              "      <td>[A, man, embody, ride, a, bicycle, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A woman and man are dancing in the rain.</td>\n",
              "      <td>A man and woman are dancing in rain.</td>\n",
              "      <td>[A, woman, and, man, be, dance, in, the, rain, .]</td>\n",
              "      <td>[A, man, and, woman, be, dance, in, rain, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Someone is drawing.</td>\n",
              "      <td>Someone is dancing.</td>\n",
              "      <td>[person, exist, draw, .]</td>\n",
              "      <td>[person, exist, dance, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A man and a woman are kissing each other.</td>\n",
              "      <td>A man and a woman are talking to each other.</td>\n",
              "      <td>[A, man, and, a, woman, embody, snog, each, ot...</td>\n",
              "      <td>[A, valet, and, a, woman, equal, lecture, to, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A woman is slicing an onion.</td>\n",
              "      <td>A woman is cutting an onion.</td>\n",
              "      <td>[A, woman, exist, slit, an, onion, .]</td>\n",
              "      <td>[A, woman, exist, cut, an, onion, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       sent1  ...                                    sent2_processed\n",
              "0                 A man is riding a bicycle.  ...              [A, man, embody, ride, a, bicycle, .]\n",
              "1   A woman and man are dancing in the rain.  ...       [A, man, and, woman, be, dance, in, rain, .]\n",
              "2                        Someone is drawing.  ...                          [person, exist, dance, .]\n",
              "3  A man and a woman are kissing each other.  ...  [A, valet, and, a, woman, equal, lecture, to, ...\n",
              "4               A woman is slicing an onion.  ...               [A, woman, exist, cut, an, onion, .]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVQ2ns3vuzuD",
        "colab_type": "text"
      },
      "source": [
        "## Jacard distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwaB6ukXuuW4",
        "colab_type": "code",
        "outputId": "18a3522b-a344-4b54-8513-8768776d8900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "result = []\n",
        "\n",
        "for index, row in train_data.iterrows():\n",
        "  result.append(jaccard_distance(set(row['sent1_processed']),\n",
        "                             set(row['sent2_processed'])))\n",
        "\n",
        "result = 1 - np.array(result)\n",
        "result[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.9       , 0.6       , 0.5       , 0.75      ,\n",
              "       0.71428571, 0.71428571, 0.4       , 0.875     , 0.7       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBkChJH7u6ML",
        "colab_type": "text"
      },
      "source": [
        "## Pearson correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWqHe_5xu2le",
        "colab_type": "code",
        "outputId": "851ee406-2676-4bd8-df66-68784259bf2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "gs = pd.read_csv('train/STS.gs.MSRvid.txt', names=['gs'])\n",
        "print(f'# rows: {len(gs)}')\n",
        "gs['gs'] = gs['gs'].astype(float)\n",
        "refs = list(gs['gs'].values)\n",
        "print(f'Gold standard: {refs[:10]}')\n",
        "tsts = result * 5\n",
        "print(f'Jaccard distance: {tsts[:10]}')\n",
        "print(f'Pearson correlation: {pearsonr(refs, tsts)[0]}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# rows: 750\n",
            "Gold standard: [5.0, 5.0, 0.3, 0.6, 4.2, 3.6, 5.0, 2.75, 5.0, 3.75]\n",
            "Jaccard distance: [5.         4.5        3.         2.5        3.75       3.57142857\n",
            " 3.57142857 2.         4.375      3.5       ]\n",
            "Pearson correlation: 0.3620718615944819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2-PjwbTD81Q",
        "colab_type": "text"
      },
      "source": [
        "## Previous and current results on training sets\n",
        "\n",
        "- Session 2 (Words), Pearson score : 0.167\n",
        "- Session 3 (Morphology), Pearson score : 0.494\n",
        "- Session 6 (Word Sense Disambiguation): 0.362"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiSEbuGzDVVl",
        "colab_type": "text"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "- It is important to map POS tags into wordnet tags, the latter just accepts a subset of tags, otherwhise, an error raises.\n",
        "\n",
        "- Calculate the lesk (WSD) algorithm to a sentence takes into account some conditions: \n",
        "\n",
        "  - If a word exists with its POS tag. This scenario is the ideal as to find the sense of that given its context is more precise due to its POS tag.\n",
        "  - If a word exists without its POS tag. Less precise, because the word lexical category is not given.\n",
        "  - If a word does not exist at all. Decide what to do, probably, just do nothing.\n",
        "\n",
        "- The results show that the performance is worse than the previous experiment (Session 1) but better than just considering words (Session 2).\n",
        "\n",
        "- One of the reasons why the score is worse is due to the fact that the lesk algorithm is weaker than other approaches. Basically, when searching for  intersections of lemmas, it can give meanings that do not have any link with the context, hence, distorting the meaning of the word.\n",
        "\n",
        "- WSD approaches are challenging, because find a good training corpus to build a robust model is not trivial as the task of  labeling the right meaning of a word given a sentence for all the possible sentences is hard, that's why a semi-supervised or unsupervised models might behave better.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IPSa26sH9ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}