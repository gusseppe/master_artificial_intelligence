{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYXOSvo2sVJw"
   },
   "source": [
    "## LAZY LEARNING EXERCISE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "USM3_DR9sVJy",
    "outputId": "b404a26e-ac21-4aa6-b0b0-7f993141c325"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from urllib import request\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tools import eda, all_steps\n",
    "from tools import preprocess as prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <th>I131_treatment</th>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>TT4_measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U_measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI_measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>TBG_measured</th>\n",
       "      <th>TBG</th>\n",
       "      <th>referral_source</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>b'F'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>...</td>\n",
       "      <td>b't'</td>\n",
       "      <td>131.0</td>\n",
       "      <td>b't'</td>\n",
       "      <td>1.73</td>\n",
       "      <td>b't'</td>\n",
       "      <td>76.0</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'SVHC'</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>...</td>\n",
       "      <td>b't'</td>\n",
       "      <td>62.0</td>\n",
       "      <td>b't'</td>\n",
       "      <td>0.94</td>\n",
       "      <td>b't'</td>\n",
       "      <td>66.0</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'other'</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>b'F'</td>\n",
       "      <td>b't'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b't'</td>\n",
       "      <td>...</td>\n",
       "      <td>b't'</td>\n",
       "      <td>116.0</td>\n",
       "      <td>b't'</td>\n",
       "      <td>0.87</td>\n",
       "      <td>b't'</td>\n",
       "      <td>134.0</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'SVI'</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>b'?'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>...</td>\n",
       "      <td>b't'</td>\n",
       "      <td>97.0</td>\n",
       "      <td>b't'</td>\n",
       "      <td>0.87</td>\n",
       "      <td>b't'</td>\n",
       "      <td>111.0</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'SVI'</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b't'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>...</td>\n",
       "      <td>b't'</td>\n",
       "      <td>83.0</td>\n",
       "      <td>b't'</td>\n",
       "      <td>0.83</td>\n",
       "      <td>b't'</td>\n",
       "      <td>101.0</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'SVHD'</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age   sex on_thyroxine query_on_thyroxine on_antithyroid_medication  sick  \\\n",
       "0  34.0  b'F'         b'f'               b'f'                      b'f'  b'f'   \n",
       "1  43.0  b'M'         b'f'               b'f'                      b'f'  b'f'   \n",
       "2  61.0  b'F'         b't'               b'f'                      b'f'  b'f'   \n",
       "3  66.0  b'?'         b'f'               b'f'                      b'f'  b'f'   \n",
       "4  61.0  b'M'         b'f'               b'f'                      b'f'  b't'   \n",
       "\n",
       "  pregnant thyroid_surgery I131_treatment query_hypothyroid  ... TT4_measured  \\\n",
       "0     b'f'            b'f'           b'f'              b'f'  ...         b't'   \n",
       "1     b'f'            b'f'           b'f'              b'f'  ...         b't'   \n",
       "2     b'f'            b'f'           b'f'              b't'  ...         b't'   \n",
       "3     b'f'            b'f'           b'f'              b'f'  ...         b't'   \n",
       "4     b'f'            b'f'           b'f'              b'f'  ...         b't'   \n",
       "\n",
       "     TT4 T4U_measured   T4U FTI_measured    FTI TBG_measured  TBG  \\\n",
       "0  131.0         b't'  1.73         b't'   76.0         b'f'  NaN   \n",
       "1   62.0         b't'  0.94         b't'   66.0         b'f'  NaN   \n",
       "2  116.0         b't'  0.87         b't'  134.0         b'f'  NaN   \n",
       "3   97.0         b't'  0.87         b't'  111.0         b'f'  NaN   \n",
       "4   83.0         b't'  0.83         b't'  101.0         b'f'  NaN   \n",
       "\n",
       "  referral_source        Class  \n",
       "0         b'SVHC'  b'negative'  \n",
       "1        b'other'  b'negative'  \n",
       "2          b'SVI'  b'negative'  \n",
       "3          b'SVI'  b'negative'  \n",
       "4         b'SVHD'  b'negative'  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'datasetsCBR/sick/sick.fold.000000.test.arff'\n",
    "\n",
    "# Read the data set\n",
    "df_test = eda.read_arff(path_data=path, url_data=None)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI</th>\n",
       "      <th>sex_?</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>on_thyroxine_f</th>\n",
       "      <th>...</th>\n",
       "      <th>T4U_measured_f</th>\n",
       "      <th>T4U_measured_t</th>\n",
       "      <th>FTI_measured_f</th>\n",
       "      <th>FTI_measured_t</th>\n",
       "      <th>TBG_measured_f</th>\n",
       "      <th>referral_source_STMW</th>\n",
       "      <th>referral_source_SVHC</th>\n",
       "      <th>referral_source_SVHD</th>\n",
       "      <th>referral_source_SVI</th>\n",
       "      <th>referral_source_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.288095</td>\n",
       "      <td>0.828221</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.343558</td>\n",
       "      <td>0.148771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.252381</td>\n",
       "      <td>0.300613</td>\n",
       "      <td>0.324709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.300613</td>\n",
       "      <td>0.265201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.173810</td>\n",
       "      <td>0.276074</td>\n",
       "      <td>0.239327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       TSH        T3       TT4       T4U       FTI  sex_?  sex_F  \\\n",
       "0  0.347826  0.008293  0.301205  0.288095  0.828221  0.174644      0      1   \n",
       "1  0.445652  0.000179  0.216867  0.123810  0.343558  0.148771      0      0   \n",
       "2  0.641304  0.000764  0.120482  0.252381  0.300613  0.324709      0      1   \n",
       "3  0.695652  0.000349  0.144578  0.207143  0.300613  0.265201      1      0   \n",
       "4  0.641304  0.002066  0.240964  0.173810  0.276074  0.239327      0      0   \n",
       "\n",
       "   sex_M  on_thyroxine_f  ...  T4U_measured_f  T4U_measured_t  FTI_measured_f  \\\n",
       "0      0               1  ...               0               1               0   \n",
       "1      1               1  ...               0               1               0   \n",
       "2      0               0  ...               0               1               0   \n",
       "3      0               1  ...               0               1               0   \n",
       "4      1               1  ...               0               1               0   \n",
       "\n",
       "   FTI_measured_t  TBG_measured_f  referral_source_STMW  referral_source_SVHC  \\\n",
       "0               1               1                     0                     1   \n",
       "1               1               1                     0                     0   \n",
       "2               1               1                     0                     0   \n",
       "3               1               1                     0                     0   \n",
       "4               1               1                     0                     0   \n",
       "\n",
       "   referral_source_SVHD  referral_source_SVI  referral_source_other  \n",
       "0                     0                    0                      0  \n",
       "1                     0                    0                      1  \n",
       "2                     0                    1                      0  \n",
       "3                     0                    1                      0  \n",
       "4                     1                    0                      0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = ['sex', 'on_thyroxine', \n",
    "                    'query_on_thyroxine', 'on_antithyroid_medication',\n",
    "                    'sick', 'pregnant', 'thyroid_surgery', 'I131_treatment',\n",
    "                    'query_hypothyroid', 'query_hyperthyroid', 'lithium',\n",
    "                    'goitre', 'tumor', 'hypopituitary', 'psych',\n",
    "                    'TSH_measured', 'T3_measured', 'TT4_measured',\n",
    "                    'T4U_measured', 'FTI_measured', 'TBG_measured',\n",
    "                    'referral_source'] # for sick dataset\n",
    "response = 'Class' # for sick dataset\n",
    "\n",
    "df_train = eda.read_arff(path_data=path, url_data=None)\n",
    "\n",
    "X_num, X_cat, y = all_steps.clean_sick(df_train)\n",
    "X = prep.join_features(X_num, X_cat)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FiLw-xusVKR"
   },
   "source": [
    "### Function that automatically reads the files and performs the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DJhGyMtsVKR"
   },
   "outputs": [],
   "source": [
    "def read_train_test_files():\n",
    "\n",
    "    train_arff_files = glob.glob('../datasets/datasetsCBR/sick/*.train.arff') # for sick dataset\n",
    "#     train_arff_files = glob.glob('../datasets/datasetsCBR/sick/*.train.arff') # for bal dataset\n",
    "#     test_arff_files = glob.glob('../datasets/datasetsCBR/bal/*.test.arff') # for bal dataset\n",
    "    test_arff_files = glob.glob('../datasets/datasetsCBR/sick/*.test.arff') # for sick dataset\n",
    "    \n",
    "\n",
    "    \n",
    "    train_test_split = []\n",
    "    for train_file, test_file in zip(train_arff_files, test_arff_files):\n",
    "        \n",
    "        # Train\n",
    "        df_train = eda.read_arff(path_data=train_file, url_data=None)\n",
    "        X_num_train, X_cat_train, y_train, encoder_train = all_steps.clean_sick(df_train)\n",
    "        X_train = prep.join_features(X_num_train, X_cat_train)\n",
    "\n",
    "        # Test\n",
    "        df_test = eda.read_arff(path_data=test_file, url_data=None)\n",
    "        X_num_test, X_cat_test, y_test, encoder_test = all_steps.clean_sick(df_train, encoder_train)\n",
    "        X_test = prep.join_features(X_num_test, X_cat_test)\n",
    "        \n",
    "\n",
    "        train_test_split.append((X_train.values, y_train.values.reshape(-1, ), \n",
    "                                 X_test.values, y_test.values.reshape(-1, )))\n",
    "    \n",
    "        \n",
    "    return train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split = read_train_test_files()\n",
    "len(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnWv-DDcsVKT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3395, 53)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_number = 1\n",
    "X_train,y_train, X_test, y_test = train_test_split[fold_number]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3395,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from scipy.stats import mode\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class KIblAlgorithm:\n",
    "    def __init__(self,r,k,voting_method,retention_type):\n",
    "        \n",
    "        \"\"\"Values for voting method:\n",
    "        'most_voted'\n",
    "        'modified plurality' \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"Values for retention_type:\n",
    "        'nr' (Never retain)\n",
    "        'ar' (Always retain)\n",
    "        'df' (Different Class retention)\n",
    "        'dd' (Degree of Desagreement)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.r = r\n",
    "        self.k = k\n",
    "        self.voting_method = voting_method\n",
    "        \n",
    "\n",
    "        assert retention_type in ['nr', 'ar', 'df', 'dd']\n",
    "        self.retention_type = retention_type\n",
    "        \n",
    "    \n",
    "    def minskowski_metric(self,p1,p2,length):\n",
    "        \"\"\"Minskowski distance between two points.\"\"\"\n",
    "        distance =0.0\n",
    "        for i in range(length):\n",
    "            distance += (abs(p1[i]-p2[i])**self.r)\n",
    "\n",
    "        return distance**(1/self.r)\n",
    "    \n",
    "    def most_voted(self,neighbors,TrainLabels):\n",
    "        Count = {}  # to get most frequent class of rows \n",
    "        for i in range(len(neighbors)):\n",
    "            label = TrainLabels[neighbors[i]]\n",
    "        \n",
    "            if label in Count:\n",
    "                Count[label] += 1\n",
    "            else:\n",
    "                Count[label] = 1\n",
    "        \n",
    "        sortcount = sorted(Count.items(), key=operator.itemgetter(1), reverse=True) # We sort from most frequent label to less frequent\n",
    "    \n",
    "        return sortcount\n",
    "    \n",
    "    def modified_plurality(self,neighbors,TrainLabels):\n",
    "        \n",
    "        Count = {}  # to get most frequent class of rows \n",
    "        for i in range(len(neighbors)):\n",
    "            label = TrainLabels[neighbors[i]]\n",
    "        \n",
    "            if label in Count:\n",
    "                Count[label] += 1\n",
    "            else:\n",
    "                Count[label] = 1\n",
    "        \n",
    "        sortcount = sorted(Count.items(), key=operator.itemgetter(1), reverse=True) # We sort from most frequent label to less frequent\n",
    "    \n",
    "        # 2) Modified plurality\n",
    "        if len(sortcount) == 1:\n",
    "            return sortcount\n",
    "        \n",
    "        while sortcount[0][1] == sortcount[1][1]:\n",
    "            neighbors = neighbors[:-1]\n",
    "            \n",
    "            Count = {}  # to get most frequent class of rows \n",
    "            for i in range(len(neighbors)):\n",
    "                label = TrainLabels[neighbors[i]]\n",
    "                if label in Count:\n",
    "                    Count[label] += 1\n",
    "                else:\n",
    "                    Count[label] = 1\n",
    "            sortcount = sorted(Count.items(), key=operator.itemgetter(1), reverse=True) # We sort from most frequent label to lenttss frequent\n",
    "\n",
    "            # print('There is a Tie')\n",
    "\n",
    "            if len(sortcount)==1:\n",
    "                # print(sortcount)\n",
    "                break\n",
    "            elif sortcount[0][1] != sortcount[1][1]:\n",
    "                # print(sortcount)\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            # print('No Tie')\n",
    "        \n",
    "        return sortcount \n",
    "    \n",
    "    def classifier(self,TrainMatrix,TestInstance,TrainLabels):\n",
    "        \"\"\"K-Instance-Based Learning algorithm\"\"\"\n",
    "        import operator\n",
    "\n",
    "        distances = {}\n",
    "        length = TrainMatrix.shape[1]\n",
    "\n",
    "        # Compute distances between one Test Incance (current test instance) and all the TrainMatrix rows\n",
    "        # for i in range(len(TrainMatrix)): # each row \n",
    "            # dist = self.minskowski_metric(TrainMatrix[i], TestInstances, length) # Selecting data by row numbers (.iloc)\n",
    "            # distances[i] = dist\n",
    "        dists = np.linalg.norm(TrainMatrix-TestInstance,ord=self.r, axis=1)\n",
    "        items = list(range(len(dists)))\n",
    "        for i in items:\n",
    "            distances[i] = dists[i]\n",
    "        sortdist = sorted(distances.items(), key=operator.itemgetter(1)) # sort in decreasing order\n",
    "\n",
    "        # Find the Train Instances that are close to the Train Instance\n",
    "        neighbors = []\n",
    "        for i in range(self.k):\n",
    "            neighbors.append(sortdist[i][0]) # we choose the index of the K most similar instances (min distance)\n",
    "        \n",
    "        if self.voting_method == 'most_voted': \n",
    "            sortcount = self.most_voted(neighbors,TrainLabels)\n",
    "        else: \n",
    "            sortcount = self.modified_plurality(neighbors,TrainLabels)\n",
    "        \n",
    "        return (sortcount[0][0],neighbors)\n",
    "    \n",
    "    \n",
    "    def update_instance_base(self, instance_index, TrainMatrix, TestInstances, TrainLabels, TestLabels, predicted, neighbors=None):\n",
    "        def instance_base_with_current_instance():\n",
    "            newTrainMatrix = TrainMatrix.copy()\n",
    "            newTrainLabels = TrainLabels.copy()\n",
    "            instance = TestInstances[instance_index]\n",
    "            label = TestLabels[instance_index]\n",
    "            return np.append(newTrainMatrix, [instance], axis=0), np.append(newTrainLabels, [label], axis=0)\n",
    "\n",
    "        if self.retention_type == 'nr':\n",
    "            return TrainMatrix, TrainLabels\n",
    "        elif self.retention_type == 'ar':\n",
    "            return instance_base_with_current_instance()\n",
    "        elif self.retention_type == 'df':\n",
    "            if TestLabels[instance_index] == predicted:\n",
    "                return TrainMatrix, TrainLabels\n",
    "            else:\n",
    "                return instance_base_with_current_instance()\n",
    "        elif self.retention_type == 'dd':\n",
    "            n_clases = len(np.unique(TestLabels))\n",
    "            majority = mode([TrainLabels[n] for n in neighbors])[0][0]\n",
    "            # print(majority)\n",
    "            n_majority_classes = len([x for x in neighbors if TrainLabels[x] == majority])\n",
    "            n_remaining_classes = len(neighbors) - n_majority_classes\n",
    "            # print(n_clases, n_majority_classes, n_remaining_classes)\n",
    "            d = n_remaining_classes/((n_clases - 1) * n_majority_classes if n_clases > 1 else 1)\n",
    "            # print(d)\n",
    "            if d >= 0.5:\n",
    "                return instance_base_with_current_instance()\n",
    "            else:\n",
    "                return TrainMatrix, TrainLabels\n",
    "        else:\n",
    "            print('Wrong retention_type')\n",
    "    \n",
    "    \n",
    "    def fit(self,TrainMatrix,TestInstances, TrainLabels, TestLabels):\n",
    "        \n",
    "        classification = []\n",
    "        \n",
    "        for i in range(len(TestInstances)):\n",
    "            label,neighbors = self.classifier(TrainMatrix,TestInstances[i],TrainLabels)\n",
    "            # print(TrainMatrix.shape)\n",
    "            TrainMatrix, TrainLabels = self.update_instance_base(i, TrainMatrix, TestInstances, TrainLabels, TestLabels, label, neighbors)\n",
    "            # print(TrainMatrix.shape)\n",
    "            classification.append((i,label))\n",
    "        \n",
    "        return classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_accuracies, result_times = [], []\n",
    "accuracies, times = {}, {}\n",
    "import time\n",
    "\n",
    "def accuracy(Y_Test,TestClassification):\n",
    "    from sklearn import metrics\n",
    "    Y_pred = [label for instance,label in TestClassification]\n",
    "    return metrics.accuracy_score(Y_Test, Y_pred)\n",
    "\n",
    "def get_experiment_id(k, r, voting_method, retention_type):\n",
    "    key = f'k={k},r={r},v={voting_method},r={retention_type}'\n",
    "    return key\n",
    "\n",
    "def execute_experiment(k, r,voting_method,retention_type, i):\n",
    "    # Read fold i\n",
    "    # Parallel(n_jobs=2)(delayed(execute_experiment)(i ** 2) for i in range(10))\n",
    "    key = get_experiment_id(k, r,voting_method,retention_type)\n",
    "    Train,Y_Train, Test, Y_Test = read_train_test_files('bal', fold_number=i+1)\n",
    "    # Evaluate\n",
    "    knn = KIblAlgorithm(k=k, r=r,voting_method=voting_method,retention_type=retention_type)\n",
    "    \n",
    "    start = time.time()\n",
    "    TestPrediction = knn.fit(Train.values,Test.values,Y_Train,Y_Test)\n",
    "    end = time.time()\n",
    "\n",
    "    return accuracy(Y_Test,TestPrediction), end-start\n",
    "\n",
    "    if key not in accuracies:\n",
    "        accuracies[key] = [accuracy(Y_Test,TestPrediction)]\n",
    "    else:\n",
    "        accuracies[key].append(accuracy(Y_Test,TestPrediction))\n",
    "\n",
    "    if key not in times:\n",
    "        times[key] = [end-start]\n",
    "    else:\n",
    "        times[key].append(end-start)\n",
    "\n",
    "\n",
    "def find_best_KIBL():\n",
    "    result_accuracies, result_times = [], []\n",
    "    for k in [1, 3, 5, 7]:\n",
    "        for r in [1,2,3]:\n",
    "            for voting_method in ['most_voted', 'modified plurality']:\n",
    "                for retention_type in ['nr', 'ar', 'df', 'dd']:\n",
    "                    # Test for 10 folds\n",
    "                    # results = Parallel(n_jobs=2)(delayed(execute_experiment)(k=k, r=r,voting_method=voting_method,retention_type=retention_type,i=i) for i in range(10))\n",
    "                    #accuracies, times = {}, {}\n",
    "                    for i in range(10):\n",
    "                        # Read fold i\n",
    "                    \n",
    "                        Train,Y_Train, Test, Y_Test = train_test_split[i]\n",
    "                        # Evaluate\n",
    "                        knn = KIblAlgorithm(k=k, r=r,voting_method=voting_method,retention_type=retention_type)\n",
    "                        \n",
    "                        start = time.time()\n",
    "                        TestPrediction = knn.fit(Train,Test,Y_Train,Y_Test)\n",
    "                        end = time.time()\n",
    "\n",
    "                        key = get_experiment_id(k,r,voting_method, retention_type)\n",
    "                        if key not in accuracies:\n",
    "                            accuracies[key] = [accuracy(Y_Test,TestPrediction)]\n",
    "                        else:\n",
    "                            accuracies[key].append(accuracy(Y_Test,TestPrediction))\n",
    "                        \n",
    "                        if key not in times:\n",
    "                            times[key] = [end-start]\n",
    "                        else:\n",
    "                            times[key].append(end-start)\n",
    "\n",
    "                    # accs = [r[0] for r in results]\n",
    "                    # tms = [r[1] for r in results]\n",
    "                    experiment_id  = get_experiment_id(k,r,voting_method, retention_type)\n",
    "                    print(f'k={k} r={r} voting={voting_method} retention={retention_type} ==> mean_accuracy={np.mean(accuracies[experiment_id])} time= {np.mean(times[experiment_id])}')\n",
    "                    # print(f'k={k} r={r} voting={voting_method} retention={retention_type} ==> mean_accuracy={np.mean(accs)} time= {np.mean(tms)}')\n",
    "                    \n",
    "                    # print(f'k={k} r={r} voting={voting_method} retention={retention_type} ==> mean_accuracy={np.mean(accuracies)} time={np.mean(times)}')\n",
    "                    # result_accuracies.append(np.mean(accuracies[experiment_id]))\n",
    "                    # result_times.append(np.mean(times[experiment_id]))\n",
    "    \n",
    "    return accuracies, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_KIBL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN provisional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class KIblAlgorithm:\n",
    "    def __init__(self, k=5, r=2, voting='most', retention='nr'):\n",
    "        self.k = k\n",
    "        self.r = r # for minkowski distance\n",
    "        self.voting = voting\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.n_classes = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_classes = len(np.unique(y))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def minskowski(self, x1, x2, r):\n",
    "        \"\"\"Minskowski distance between two points.\"\"\"\n",
    "#         distance =0.0\n",
    "#         for k in range(length):\n",
    "#             distance += (abs(p1[k]-p2[k])**r)\n",
    "\n",
    "#         return distance**(1/r)\n",
    "\n",
    "        distance = np.sum(np.abs(x1-x2) ** r, axis=1) ** (1/r)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def get_policy(self, distances, voting='most'):\n",
    "        \n",
    "        if voting == 'most':\n",
    "            votes = np.zeros(self.n_classes, dtype=np.int)\n",
    "\n",
    "            # find k closet neighbors and vote\n",
    "            # argsort returns the indices that would sort an array\n",
    "            # so indices of nearest neighbors\n",
    "            # we take self.k first\n",
    "            for neighbor_id in np.argsort(distances)[:self.k]:\n",
    "                # this is a label corresponding to one of the closest neighbor\n",
    "                try:\n",
    "                    neighbor_label = self.y[neighbor_id]\n",
    "                # which updates votes array\n",
    "                    votes[neighbor_label] += 1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "#             print(votes)\n",
    "            return np.argmax(votes)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "\n",
    "        y_pred = []\n",
    "\n",
    "        for x in X_test:\n",
    "            distances = self.minskowski(self.X, x, self.r)\n",
    "#             print(distances)\n",
    "            label = self.get_policy(distances, voting=self.voting)\n",
    "            y_pred.append(label)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class reductionKIblAlgorithm:\n",
    "    def __init__(self, k=5, r=2, \n",
    "                 voting='most', \n",
    "                 retention='nr',\n",
    "                 reduction='cnn',\n",
    "                 random_state=42):\n",
    "\n",
    "        self.k = k\n",
    "        self.r = r\n",
    "        self.voting = voting\n",
    "        self.retention = retention\n",
    "        self.reduction = reduction\n",
    "        self.random_state = random_state\n",
    "        self.knn = KIblAlgorithm(k, r, voting, retention)\n",
    "        self.knn_reduced = self.knn\n",
    "        self.indexes_rm = None\n",
    "        self.X_reduced = None\n",
    "        self.y_reduced = None\n",
    "        \n",
    "    def apply_reduction(self, X, y, \n",
    "                        method='cnn', random_state=42):\n",
    "        \n",
    "        random_instance = np.random.RandomState(random_state)\n",
    "        \n",
    "        def cnn(X_train, y_train):\n",
    "            \"\"\"\n",
    "                Incremental algorithm. Begins with random instances \n",
    "                belonging to each class, then increasing the training \n",
    "                data by inserting those instances that misclassified.\n",
    "            \"\"\"\n",
    "            # Start gathering one instance for each class, randomly.\n",
    "            classes = np.unique(y_train)\n",
    "            indexes_reduced = []\n",
    "            for cl in classes:\n",
    "                y_indexes = np.where(y_train == cl)[0]\n",
    "                index = random_instance.choice(y_indexes, 1)[0]\n",
    "                indexes_reduced.append(index)\n",
    "\n",
    "            x_train_reduced = X_train[indexes_reduced]\n",
    "            y_train_reduced = y_train[indexes_reduced]\n",
    "\n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "\n",
    "                y_pred_instance = best_knn.predict(np.asarray([x_instance]))\n",
    "          \n",
    "                # If misclassified, add to reduced set.\n",
    "                if y_pred_instance != y_instance:\n",
    "                    x_train_reduced = np.vstack([x_train_reduced, x_instance])\n",
    "                    y_train_reduced = np.hstack([y_train_reduced, y_instance])\n",
    "                    indexes_reduced = np.hstack([indexes_reduced, index])\n",
    "\n",
    "            # Only unique indexes\n",
    "            indexes_reduced = np.unique(indexes_reduced)\n",
    "            \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced\n",
    "        \n",
    "        def enn(X_train, y_train):\n",
    "            \"\"\"\n",
    "                Non-incremental algorithm. Each instance is removed if it \n",
    "                does not agree with the majority of its knn.\n",
    "            \n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with all training data.\n",
    "            indexes_reduced = np.arange(len(X_train))\n",
    "\n",
    "            x_train_reduced = X_train\n",
    "            y_train_reduced = y_train\n",
    "\n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "                y_pred_instance = best_knn.predict(np.asarray([x_instance]))\n",
    "\n",
    "                # If misclassified, remove from the initial set.\n",
    "                if y_pred_instance != y_instance:\n",
    "                    x_train_reduced = np.delete(x_train_reduced, [index], axis=0)\n",
    "                    y_train_reduced = np.delete(y_train_reduced, [index], axis=0)\n",
    "                    indexes_reduced = np.delete(indexes_reduced, [index], axis=0)\n",
    "            \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced           \n",
    "        \n",
    "        def ib3(X_train, y_train):\n",
    "            \"\"\"\n",
    "                It is an incremental algorith. It addresses the IB2's problem \n",
    "                of keeping noisy instances by retaining only acceptable \n",
    "                misclassified instances.\n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with the first element.\n",
    "            x_train_reduced = np.reshape(X_train[0], (1, -1))\n",
    "            y_train_reduced = np.reshape(y_train[0], (1, -1))\n",
    "            acceptable = np.array([0])\n",
    "            \n",
    "            lower = lambda p,z,n: (p + (z**2)/(2*n) - z*((p*(1-p)/n + (z**2)/(4*n**2)))**0.5)/(1 + (z**2)/n)\n",
    "            upper = lambda p,z,n: (p + (z**2)/(2*n) + z*((p*(1-p)/n + (z**2)/(4*n**2)))**0.5)/(1 + (z**2)/n)\n",
    "               \n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "#                 print(x_train_reduced)\n",
    "                y_pred_instance = best_knn.predict(np.asarray([x_instance]))\n",
    "\n",
    "                # This part is similar to IB2\n",
    "                if y_pred_instance != y_instance:\n",
    "                    x_train_reduced = np.vstack([x_train_reduced, x_instance])\n",
    "                    acceptable = np.hstack([acceptable, index])\n",
    "                \n",
    "                    \n",
    "                incorrect_class = 0\n",
    "                correct_class = 0\n",
    "                # This part differ from IB2, just acceptable instance are kept.\n",
    "                # Count the number of incorrect and correct classification\n",
    "                for x_instance_reduced in x_train_reduced:\n",
    "                    best_knn = self.knn\n",
    "                    best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "                    y_pred_instance_reduced = best_knn.predict(np.asarray([x_instance_reduced]))\n",
    "                    \n",
    "                    if y_pred_instance_reduced != y_instance:\n",
    "                        incorrect_class += 1\n",
    "                    else:\n",
    "                        correct_class += 1\n",
    "                \n",
    "                n = incorrect_class + correct_class\n",
    "                p = correct_class / n\n",
    "                \n",
    "                # For acceptance\n",
    "                z = 0.9\n",
    "                lower_bound = lower(p, z, n)\n",
    "                upper_bound = upper(p, z, n)\n",
    "#                 print(lower_bound, upper_bound, incorrect_class, correct_class)\n",
    "                if (incorrect_class/n <= lower_bound) or (correct_class/n >= upper_bound):\n",
    "                    acceptable = np.hstack([acceptable, index])\n",
    "                \n",
    "                # For removing\n",
    "                z = 0.7\n",
    "                lower_bound = lower(p, z, n)\n",
    "                upper_bound = upper(p, z, n)\n",
    "                \n",
    "                if (incorrect_class/n <= lower_bound) or (correct_class/n >= upper_bound):\n",
    "                    acceptable = np.delete(acceptable, [index], axis=0)                 \n",
    "\n",
    "            x_train_reduced = X_train[acceptable]\n",
    "            y_train_reduced = y_train[acceptable]\n",
    "            indexes_reduced = acceptable\n",
    "            \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced    \n",
    "  \n",
    "        def drop1(X_train, y_train):\n",
    "            \"\"\"\n",
    "                This is a non-incremental algorithm. From the paper, \n",
    "                it can be translated as: \"It goes over the dataset in the provided order, \n",
    "                and removes those instances whose removal does not decrease \n",
    "                the accuracy of the 1-NN rule in the remaining dataset\"\n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with all training data.\n",
    "            indexes_reduced = np.arange(len(X_train))\n",
    "\n",
    "            x_train_reduced = X_train\n",
    "            y_train_reduced = y_train\n",
    "\n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "#                 print(index)\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "                y_pred_initial = best_knn.predict(x_train_reduced)\n",
    "                \n",
    "                acc_initial = accuracy_score(y_pred_initial, y_train_reduced)\n",
    "                \n",
    "\n",
    "                # Removes one instance from the initial set.\n",
    "                x_train_reduced_t = np.delete(x_train_reduced, [index], axis=0)\n",
    "                y_train_reduced_t = np.delete(y_train_reduced, [index], axis=0)\n",
    "                indexes_reduced_t = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "                # Fit again using a 1-nn in the remaining data.\n",
    "                best_1nn = KIblAlgorithm(k=self.k, r=self.r, \n",
    "                                         voting=self.voting, \n",
    "                                         retention=self.retention)\n",
    "                \n",
    "                best_1nn.fit(x_train_reduced_t, y_train_reduced_t)\n",
    "                y_pred_1nn_without_instance = best_1nn.predict(x_train_reduced_t)           \n",
    "                \n",
    "                acc_after = accuracy_score(y_pred_1nn_without_instance, y_train_reduced_t)\n",
    "                \n",
    "                # if accuracy after removing the instance is greater than initial, then \n",
    "                # remove from the initial set.\n",
    "                if acc_after >= acc_initial:\n",
    "                    x_train_reduced = np.delete(x_train_reduced, [index], axis=0)\n",
    "                    y_train_reduced = np.delete(y_train_reduced, [index], axis=0)\n",
    "                    indexes_reduced = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced      \n",
    "        \n",
    "        def drop2(X_train, y_train):\n",
    "            \"\"\"\n",
    "                This is a non-incremental algorithm. Similar to DROP1 but \n",
    "                the accuracy of the 1-NN rule is done in the original dataset\".\n",
    "                \n",
    "                Note: A preprocessing is needed before calculating the accuracy:\n",
    "                \"starts with those which are furthest from their nearest \"enemy\" \n",
    "                (two instances are said to be \"enemies\" if they belong to different classes)\".\n",
    "                Hence, this is a partial implementation of drop2.\n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with all training data.\n",
    "            indexes_reduced = np.arange(len(X_train))\n",
    "\n",
    "            x_train_reduced = X_train\n",
    "            y_train_reduced = y_train\n",
    "            \n",
    "            \n",
    "            best_knn = self.knn\n",
    "            best_knn.fit(X_train, y_train)\n",
    "            y_pred_initial = best_knn.predict(X_train)\n",
    "            acc_initial = accuracy_score(y_pred_initial, y_train)\n",
    "            \n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "\n",
    "                # Removes one instance from the initial set.\n",
    "                x_train_reduced_t = np.delete(x_train_reduced, [index], axis=0)\n",
    "                y_train_reduced_t = np.delete(y_train_reduced, [index], axis=0)\n",
    "                indexes_reduced_t = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "                # Fit again using a 1-nn in the remaining data.\n",
    "                best_1nn = KIblAlgorithm(k=self.k, r=self.r, \n",
    "                                         voting=self.voting, \n",
    "                                         retention=self.retention)\n",
    "                \n",
    "                best_1nn.fit(x_train_reduced_t, y_train_reduced_t)\n",
    "                y_pred_1nn_without_instance = best_1nn.predict(x_train_reduced_t)           \n",
    "                \n",
    "                acc_after = accuracy_score(y_pred_1nn_without_instance, y_train_reduced_t)\n",
    "                \n",
    "                # if accuracy after removing the instance is greater than initial, then \n",
    "                # remove from the initial set.\n",
    "                if acc_after >= acc_initial:\n",
    "                    x_train_reduced = np.delete(x_train_reduced, [index], axis=0)\n",
    "                    y_train_reduced = np.delete(y_train_reduced, [index], axis=0)\n",
    "                    indexes_reduced = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced         \n",
    "        \n",
    "        if method == 'cnn':\n",
    "            return cnn(X, y)\n",
    "        elif method == 'enn':\n",
    "            return enn(X, y)\n",
    "        elif method == 'ib3':\n",
    "            return ib3(X, y)\n",
    "        elif method == 'drop1':\n",
    "            return drop1(X, y)\n",
    "        elif method == 'drop2':\n",
    "            return drop2(X, y)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X_reduced, y_reduced, indexes_rm = self.apply_reduction(X, y, \n",
    "                                             self.reduction,\n",
    "                                             self.random_state)\n",
    "        \n",
    "        self.knn_reduced.fit(X_reduced, y_reduced)\n",
    "        \n",
    "        self.X_reduced = X_reduced\n",
    "        self.y_reduced = y_reduced\n",
    "        self.indexes_rm = indexes_rm\n",
    "        \n",
    "        return self\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "\n",
    "        y_pred = self.knn_reduced.predict(X)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing knn vs reduced_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3395,53) (52,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ae7bad62002c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ccc66047d8cf>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminskowski\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;31m#             print(distances)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ccc66047d8cf>\u001b[0m in \u001b[0;36mminskowski\u001b[0;34m(self, x1, x2, r)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#         return distance**(1/r)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3395,53) (52,) "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KIblAlgorithm(k=5, r=1, \n",
    "                    voting='most', \n",
    "                    retention='nr')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "reduced_knn = reductionKIblAlgorithm(k=5, r=1, \n",
    "                    voting='most', \n",
    "                    retention='nr',\n",
    "                    reduction='drop1')\n",
    "reduced_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_reduced = reduced_knn.predict(X_test)\n",
    "accuracy_score(y_pred_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bal_lazy_learning-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
